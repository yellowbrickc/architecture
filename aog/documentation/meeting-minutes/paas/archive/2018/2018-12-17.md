# Meeting Minutes

## degradation of Isolation

### bekannte Probleme

- S3 pusher kann unregelmäßig nicht zu AWS S3 pushen (siehe https://logs.sub.rocks/goto/ce8b9b71d50f27629bff8f0485bd5ba5)
- (beim deploy auf Isolation starten die Pods (application) nicht) 
    - z.B https://ci.sub.rocks/view/Subscription%20Platform/view/RA/job/reportinganalytics_qualitygate_system/481/ und der darauf folgende auch
- gestartete Pods auf Isolation laufen in ein timeout (ping/ready)
- unregelmäßig kann im Test der selenium Pod auf target ENV (zB. isolation => early) nicht zugreifen (auch im gleichen Test run - bei 95% konnte aufgelöst werden, und dann auf einmal nicht mehr)

### Auswirkungen

- R&A muss großen Zeitaufwand / Latenzen für Feedback in Kauf nehmen
- alle Teams haben einen nicht verlässlichen / unbrauchbaren Test-Zustand

### Maßnahmen

- @PaaS: check Unterschiede zwischen den K8s Isoaltion Nodes (resolve.conf)
- @PaaS: test kube-dns auf einen Pod runter skalieren (flackert es danach immer noch?)
- @PaaS: restart kube-dns (gibt hier eine Änderung!?)
- @R&A: beim nächsten Auftreten (Pods starten nicht), genauer rein schauen (K8s)
- @all: check ob bei kafka, trailing dot angehangen ist (Bsp: `eventbus-integration01.sub.rocks.:9082`)

## nächstes Mal

- [pod disruptions](https://kubernetes.io/docs/concepts/workloads/pods/disruptions)
- update policy
- ingress - error page
- environment vs. cluster (env != isolation !?)

- Priorisierung
